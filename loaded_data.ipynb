{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import requests\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from sklearn.preprocessing import normalize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data3.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# open csv\n",
    "tfidf = pd.read_csv('tfidf.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=None\n",
    "import cv2\n",
    "\n",
    "def adjust_brightness_and_contrast(image, brightness=0, contrast=0):\n",
    "        # Alpha controls contrast; Beta controls brightness.\n",
    "        alpha = 1 + contrast / 127\n",
    "        beta = brightness\n",
    "        adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "        return adjusted_image\n",
    "\n",
    "def preprocess(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = cv2.imdecode(np.frombuffer(response.content, np.uint8), -1)\n",
    "    if image is None:\n",
    "        return None\n",
    "    # image_height, image_width = image.shape[:2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #pixel normalisation\n",
    "    def normalize_image(image):\n",
    "        normalized_image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        return normalized_image\n",
    "\n",
    "    image = normalize_image(image)\n",
    "    \n",
    "\n",
    "    #brightness and contrast adjustment\n",
    "    def calculate_brightness_and_contrast(image):\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        mean, std_dev = cv2.meanStdDev(gray_image)\n",
    "        return mean[0][0], std_dev[0][0]\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    mean_brightness, std_dev_contrast = calculate_brightness_and_contrast(image)\n",
    "\n",
    "    # Set a threshold for deciding whether to adjust brightness and contrast\n",
    "    brightness_threshold = 20  \n",
    "    contrast_threshold = 10 \n",
    "\n",
    "    # Adjust brightness and contrast only if needed\n",
    "    if mean_brightness < brightness_threshold or std_dev_contrast < contrast_threshold:\n",
    "        brightness = 20  \n",
    "        contrast = 20  \n",
    "        adjusted_image = adjust_brightness_and_contrast(image, brightness=brightness, contrast=contrast)\n",
    "    else:\n",
    "        adjusted_image = image\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGE PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vgg16\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg16_model = vgg16(pretrained=True)\n",
    "vgg16_model.eval()\n",
    "\n",
    "# Define a function to extract features using VGG16\n",
    "def extract_features_vgg16(image):\n",
    "    img = cv2.resize(image, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_tensor = transforms.ToTensor()(img)\n",
    "    img_tensor = torch.unsqueeze(img_tensor, 0)\n",
    "    with torch.no_grad():\n",
    "        features = vgg16_model.features(img_tensor)\n",
    "    features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "    features = features.squeeze().numpy()\n",
    "    return features.flatten()\n",
    "\n",
    "# Define a function to extract normalized features using VGG16\n",
    "def extract_features_normalized_vgg16(image):\n",
    "    extracted_features = extract_features_vgg16(image)\n",
    "    normalized_features = normalize([extracted_features], norm='l2')\n",
    "    return normalized_features[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine_similarity(vector_a, vector_b):\n",
    "    dot_product = np.dot(vector_a, vector_b)\n",
    "    norm_a = np.linalg.norm(vector_a)\n",
    "    norm_b = np.linalg.norm(vector_b)\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  check similarity between two images\n",
    "def check_similarity(image_url1, image_url2):\n",
    "    image1 = preprocess(image_url1)\n",
    "    image2 = preprocess(image_url2)\n",
    "    if image1 is None or image2 is None:\n",
    "        return None\n",
    "    features1 = extract_features_normalized_vgg16(image1)\n",
    "    features2 = extract_features_normalized_vgg16(image2)\n",
    "    similarity = cosine_similarity(features1, features2)\n",
    "    return similarity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Image_Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3452</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>love vintag spring vintag strat good tension g...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1205</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>work great guitar bench mat rug enough abus ta...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.563436856848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1708</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>use everyth acoust bass ukulel know smaller mo...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2078</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>great price good qualiti didnt quit match radi...</td>\n",
       "      <td>[[0.008398145451137908, 0.0022459865717929435,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>bought bass split time primari bass dean edg m...</td>\n",
       "      <td>[[0.015007795081277633, 0.009100475550438039, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Image  \\\n",
       "0        3452  [https://images-na.ssl-images-amazon.com/image...   \n",
       "1        1205  [https://images-na.ssl-images-amazon.com/image...   \n",
       "2        1708  [https://images-na.ssl-images-amazon.com/image...   \n",
       "3        2078  [https://images-na.ssl-images-amazon.com/image...   \n",
       "4         801  [https://images-na.ssl-images-amazon.com/image...   \n",
       "\n",
       "                                         Review Text  \\\n",
       "0  love vintag spring vintag strat good tension g...   \n",
       "1  work great guitar bench mat rug enough abus ta...   \n",
       "2  use everyth acoust bass ukulel know smaller mo...   \n",
       "3  great price good qualiti didnt quit match radi...   \n",
       "4  bought bass split time primari bass dean edg m...   \n",
       "\n",
       "                                       Image_Vectors  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.563436856848...  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [[0.008398145451137908, 0.0022459865717929435,...  \n",
       "4  [[0.015007795081277633, 0.009100475550438039, ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  preprorcess revierw texts\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer as ps\n",
    "\n",
    "# Download the stopwords corpus if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_review_text(review_text):\n",
    "\n",
    "    review_text = str(review_text)\n",
    "    review_text = review_text.lower()\n",
    "    review_text = re.sub(r'[^\\w\\s]', '', review_text)\n",
    "    # remove stop words\n",
    "    review_text = ' '.join([word for word in review_text.split() if word not in stop_words])\n",
    "    # do stemming\n",
    "    review_text = ' '.join([ps().stem(word) for word in review_text.split()])\n",
    "    return review_text\n",
    "\n",
    "\n",
    "\n",
    "# data['Review Text'] = data['Review Text'].apply(preprocess_review_text)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def tokenize(text):\n",
    "    # Split text into tokens (words)\n",
    "    return text.split()\n",
    "\n",
    "def calculate_tf(text):\n",
    "    # Calculate term frequency (TF) for each word in the text\n",
    "    tokens = tokenize(text)\n",
    "    word_count = Counter(tokens)\n",
    "    total_words = len(tokens)\n",
    "    tf = {word: count / total_words for word, count in word_count.items()}\n",
    "    return tf\n",
    "\n",
    "def calculate_idf(documents):\n",
    "    # Calculate inverse document frequency (IDF) for each word\n",
    "    total_documents = len(documents)\n",
    "    all_words = set([word for document in documents for word in tokenize(document)])\n",
    "    idf = {}\n",
    "    for word in all_words:\n",
    "        doc_count = sum([1 for document in documents if word in tokenize(document)])\n",
    "        idf[word] = math.log10(total_documents / doc_count)\n",
    "    return idf\n",
    "\n",
    "def calculate_tfidf(text, idf):\n",
    "    # Calculate TF-IDF for each word in the text using precomputed IDF values\n",
    "    \n",
    "    tf = calculate_tf(text)\n",
    "    tfidf = {word: tf[word] * idf[word] for word in tf}\n",
    "    return tfidf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Image_Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3452</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>love vintag spring vintag strat good tension g...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1205</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>work great guitar bench mat rug enough abus ta...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.563436856848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1708</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>use everyth acoust bass ukulel know smaller mo...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2078</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>great price good qualiti didnt quit match radi...</td>\n",
       "      <td>[[0.008398145451137908, 0.0022459865717929435,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>801</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>bought bass split time primari bass dean edg m...</td>\n",
       "      <td>[[0.015007795081277633, 0.009100475550438039, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Image  \\\n",
       "0        3452  [https://images-na.ssl-images-amazon.com/image...   \n",
       "1        1205  [https://images-na.ssl-images-amazon.com/image...   \n",
       "2        1708  [https://images-na.ssl-images-amazon.com/image...   \n",
       "3        2078  [https://images-na.ssl-images-amazon.com/image...   \n",
       "4         801  [https://images-na.ssl-images-amazon.com/image...   \n",
       "\n",
       "                                         Review Text  \\\n",
       "0  love vintag spring vintag strat good tension g...   \n",
       "1  work great guitar bench mat rug enough abus ta...   \n",
       "2  use everyth acoust bass ukulel know smaller mo...   \n",
       "3  great price good qualiti didnt quit match radi...   \n",
       "4  bought bass split time primari bass dean edg m...   \n",
       "\n",
       "                                       Image_Vectors  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.563436856848...  \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3  [[0.008398145451137908, 0.0022459865717929435,...  \n",
       "4  [[0.015007795081277633, 0.009100475550438039, ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the first unnamed coluumn as id\n",
    "data = data.rename(columns={'Unnamed: 0': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>love</th>\n",
       "      <th>vintag</th>\n",
       "      <th>spring</th>\n",
       "      <th>strat</th>\n",
       "      <th>good</th>\n",
       "      <th>tension</th>\n",
       "      <th>great</th>\n",
       "      <th>stabil</th>\n",
       "      <th>float</th>\n",
       "      <th>bridg</th>\n",
       "      <th>...</th>\n",
       "      <th>mayer</th>\n",
       "      <th>importantli</th>\n",
       "      <th>toneprint</th>\n",
       "      <th>stringthru</th>\n",
       "      <th>stopflair</th>\n",
       "      <th>biggi</th>\n",
       "      <th>accord</th>\n",
       "      <th>screenshot</th>\n",
       "      <th>amazoncom</th>\n",
       "      <th>piti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060264</td>\n",
       "      <td>0.232282</td>\n",
       "      <td>0.295898</td>\n",
       "      <td>0.090928</td>\n",
       "      <td>0.045850</td>\n",
       "      <td>0.13962</td>\n",
       "      <td>0.032906</td>\n",
       "      <td>0.13962</td>\n",
       "      <td>0.168018</td>\n",
       "      <td>0.097727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029902</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021461</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057313</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.041133</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5090 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       love    vintag    spring     strat      good  tension     great  \\\n",
       "0  0.060264  0.232282  0.295898  0.090928  0.045850  0.13962  0.032906   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.029902  0.00000  0.021461   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.057313  0.00000  0.041133   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.010730   \n",
       "\n",
       "    stabil     float     bridg  ...  mayer  importantli  toneprint  \\\n",
       "0  0.13962  0.168018  0.097727  ...    0.0          0.0        0.0   \n",
       "1  0.00000  0.000000  0.000000  ...    0.0          0.0        0.0   \n",
       "2  0.00000  0.000000  0.000000  ...    0.0          0.0        0.0   \n",
       "3  0.00000  0.000000  0.000000  ...    0.0          0.0        0.0   \n",
       "4  0.00000  0.000000  0.000000  ...    0.0          0.0        0.0   \n",
       "\n",
       "   stringthru  stopflair  biggi  accord  screenshot  amazoncom  piti  \n",
       "0         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n",
       "1         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n",
       "2         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n",
       "3         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n",
       "4         0.0        0.0    0.0     0.0         0.0        0.0   0.0  \n",
       "\n",
       "[5 rows x 5090 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  make a tdidf matrix \n",
    "# 1. Calculate IDF for the dataset\n",
    "idf = calculate_idf(data['Review Text'].tolist())\n",
    "\n",
    "# 2. Calculate TF-IDF for each document\n",
    "tfidf_matrix = []\n",
    "for document in data['Review Text'].tolist():\n",
    "    tfidf = calculate_tfidf(document, idf)\n",
    "    tfidf_matrix.append(tfidf)\n",
    "\n",
    "# 3. Convert the TF-IDF matrix to a DataFrame\n",
    "tfidf = pd.DataFrame(tfidf_matrix)\n",
    "tfidf = tfidf.fillna(0)\n",
    "tfidf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the query text to a dictionary of word frequenciesdef convertText\n",
    "def convert_text_to_tfidf(text, idf):\n",
    "    tfidf = calculate_tfidf(text, idf)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostSimilarReviews(queryText):\n",
    "    queryText=preprocess_review_text(queryText)\n",
    "    \n",
    "    idf=calculate_idf(data['Review Text'].tolist())\n",
    "    queryText=\" \".join([word for word in queryText.split() if word in idf])\n",
    "    # Convert the query text to a dictionary of word frequencies\n",
    "    queryText = convert_text_to_tfidf(queryText, idf)\n",
    "    # Calculate the query vector\n",
    "    queryVector = np.zeros(len(tfidf.columns))\n",
    "    for word in queryText:\n",
    "        if word in tfidf.columns:\n",
    "            queryVector[tfidf.columns.get_loc(word)] = queryText[word]\n",
    "    # Calculate the cosine similarity between the query vector and all the document vectors\n",
    "    cosineSimilarities = {}\n",
    "    for i in range(len(tfidf)):\n",
    "        docVector = tfidf.iloc[i].values\n",
    "        cosineSimilarities[i] = np.dot(queryVector, docVector) / (np.linalg.norm(queryVector) * np.linalg.norm(docVector))\n",
    "    # Sort the cosine similarities\n",
    "    sortedCosineSimilarities = sorted(cosineSimilarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    #  also return their respective scoerees\n",
    "    indices= sortedCosineSimilarities[:3]\n",
    "    scores=[i[1] for i in sortedCosineSimilarities[:3]]\n",
    "    return indices, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cosine similarity between two texts\n",
    "def textSimilarity(query_text1, query_text2):\n",
    "    query_text1=preprocess_review_text(query_text1)\n",
    "    query_text2=preprocess_review_text(query_text2)\n",
    "    idf=calculate_idf(data['Review Text'].tolist())\n",
    "    query_text1=\" \".join([word for word in query_text1.split() if word in idf])\n",
    "    query_text2=\" \".join([word for word in query_text2.split() if word in idf])\n",
    "    # Convert the query text to a dictionary of word frequencies\n",
    "    queryText1 = convert_text_to_tfidf(query_text1, idf)\n",
    "    queryText2 = convert_text_to_tfidf(query_text2, idf)\n",
    "    # Calculate the query vector\n",
    "    queryVector1 = np.zeros(len(tfidf.columns))\n",
    "    queryVector2 = np.zeros(len(tfidf.columns))\n",
    "    for word in queryText1:\n",
    "        if word in tfidf.columns:\n",
    "            queryVector1[tfidf.columns.get_loc(word)] = queryText1[word]\n",
    "    for word in queryText2:\n",
    "        if word in tfidf.columns:\n",
    "            queryVector2[tfidf.columns.get_loc(word)] = queryText2[word]\n",
    "    # Calculate the cosine similarity between the query vector and all the document vectors\n",
    "    docVector1 = queryVector1\n",
    "    docVector2 = queryVector2\n",
    "    cosineSimilarity = np.dot(docVector1, docVector2) / (np.linalg.norm(docVector1) * np.linalg.norm(docVector2))\n",
    "    return cosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 0.46496524195976735)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print an example\n",
    "query_text = \"I love the product\"\n",
    "mostSimilarReviews(query_text)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use fender lock tuner five year variou strat tele definit help tune stabil way faster restr break\n",
      "went fender chrome nonlock fender gold lock made guitar look beauti play beauti think lock tuner way go new lock tuner look youtub instruct\n",
      "tele perfect thank much\n"
     ]
    }
   ],
   "source": [
    "#  print the review text of the top 5 similar reviews to the qeury text\n",
    "for i, in mostSimilarReviews('I have been using Fender locking tuners for about five years on variousstrats and teles. Definitely helps with tuning stability and way faster to restring ifthere is a break.'):\n",
    "    print(data.iloc[i[0]]['Review Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(575, 0.5101304632627585),\n",
       " (652, 0.43318719702258773),\n",
       " (516, 0.40847325497715176)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  find the most similar images top 5 given an image url\n",
    "def find_similar_images(image_url):\n",
    "    image = preprocess(image_url)\n",
    "    if image is None:\n",
    "        return None\n",
    "    features = extract_features_normalized_vgg16(image)\n",
    "    # print(features)\n",
    "\n",
    "    similarities = {}\n",
    "    for i ,x in enumerate(data['Image_Vectors']):\n",
    "        vectors=x\n",
    "        max_sim=0\n",
    "        for vector in vectors:\n",
    "            # print(vector)   \n",
    "            \n",
    "            similarity = cosine_similarity(features, vector)\n",
    "            if similarity > max_sim:\n",
    "                max_sim = similarity\n",
    "\n",
    "        similarities[i] = max_sim\n",
    "    similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:3]\n",
    "\n",
    "\n",
    "find_similar_images(\"https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Image retrieval\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/61n284XL9HL._SY88.jpg']\n",
      "Review Text:  easi heck put opinion better sperzel took liter 10 minut put mim strat thing ill say probabl need setup remov tuner remov string guid tree headstock go chang angl bridg littl bit awar\n",
      "Image Similarity Score:  0.5101304632627585\n",
      "Review Similarity Score:  0.05949794376613932\n",
      "Composite Similarity Score:  0.2848142035144489\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/719-SDMiOoL._SY88.jpg']\n",
      "Review Text:  lock tuner look great keep tune good qualiti materi construct excel upgrad guitar drill addit hole instal neck alreadi come predril hole drop right otherwis need buy guitar tuner pin drill jig also avail amazon\n",
      "Image Similarity Score:  0.43318719702258773\n",
      "Review Similarity Score:  0.12725617802413502\n",
      "Composite Similarity Score:  0.2802216875233614\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/51V0K2tgLUL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/5134EWdp6lL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/51m2jBw+onL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/51Xrb4h7gsL._SY88.jpg']\n",
      "Review Text:  love guitar honestli never held squir brand strat compar everyth ive held play heard past guitar realli give best bang buck especi your like pretti much poor dirt thought guitar cheap id probabl want get small upgrad im pretti content got first 10 minut play recommend guitar pretti much anyon want strat incred qualiti price\n",
      "Image Similarity Score:  0.40847325497715176\n",
      "Review Similarity Score:  0.04668474922183107\n",
      "Composite Similarity Score:  0.22757900209949142\n",
      "Using Review retrieval\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg']\n",
      "Review Text:  use fender lock tuner five year variou strat tele definit help tune stabil way faster restr break\n",
      "Review Similarity Score:  1.0000000000000002\n",
      "Image Similarity Score:  1.0\n",
      "Composite Similarity Score:  1.0\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/61DvLcapd8L._SY88.jpg']\n",
      "Review Text:  went fender chrome nonlock fender gold lock made guitar look beauti play beauti think lock tuner way go new lock tuner look youtub instruct\n",
      "Review Similarity Score:  0.2583316379736251\n",
      "Image Similarity Score:  0.14769622889754241\n",
      "Composite Similarity Score:  0.20301393343558374\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/71mhnYAH5VL._SY88.jpg']\n",
      "Review Text:  tele perfect thank much\n",
      "Review Similarity Score:  0.17164894927714294\n",
      "Image Similarity Score:  0.22529995951374931\n",
      "Composite Similarity Score:  0.19847445439544614\n",
      "Composite Similarity\n",
      "Image URL 754\n",
      "Composite Similarity Score:  0.5233423746109156\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage URL\u001b[39m\u001b[38;5;124m\"\u001b[39m,key)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComposite Similarity Score: \u001b[39m\u001b[38;5;124m\"\u001b[39m,value)\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview Text: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReview Text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview Similarity Score: \u001b[39m\u001b[38;5;124m\"\u001b[39m,textSimilarity(review,data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mkey][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])) \n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage Similarity Score: \u001b[39m\u001b[38;5;124m\"\u001b[39m,check_similarity(image_urlx,key))\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# take the input image link from user\n",
    "image_urlx = input(\"Enter the image url: \")\n",
    "# #  take users input for the review\n",
    "review = input(\"Enter the review: \")\n",
    "\n",
    "# composite dictionary to store these results\n",
    "composite = {}\n",
    "\n",
    "\n",
    "#  find the most similar images top 3 images \n",
    "similar_images = find_similar_images(image_urlx)\n",
    "print(\"Using Image retrieval\")\n",
    "for i in similar_images:\n",
    "    print(\"Image URL\",image_url:=data.iloc[i[0]]['Image'])\n",
    "    print(\"Review Text: \", data.iloc[i[0]]['Review Text'])\n",
    "    print(\"Image Similarity Score: \",i[1] )\n",
    "    review1= data.iloc[i[0]]['Review Text']\n",
    "    print(\"Review Similarity Score: \",textSimilarity(review,review1)) \n",
    "    print(\"Composite Similarity Score: \",(i[1]+textSimilarity(review,review1))/2)\n",
    "    composite[i[0]] =(i[1]+textSimilarity(review,review1))/2\n",
    "\n",
    "print(\"Using Review retrieval\")\n",
    "similarReviews1 = mostSimilarReviews(review)[0]\n",
    "for i in similarReviews1:\n",
    "    print(\"Image URL\",data.iloc[i[0]]['Image'])\n",
    "    print(\"Review Text: \", data.iloc[i[0]]['Review Text'])\n",
    "    print(\"Review Similarity Score: \",i[1] )\n",
    "    image_urls1= data.iloc[i[0]]['Image']\n",
    "    maxImageSim=0\n",
    "    for x in image_urls1:\n",
    "        maxImageSim=max(maxImageSim,check_similarity(image_urlx,x))\n",
    "    print(\"Image Similarity Score: \",maxImageSim)\n",
    "    print(\"Composite Similarity Score: \",(i[1]+maxImageSim)/2)\n",
    "    composite[i[0]] =(i[1]+textSimilarity(review,review1))/2\n",
    "\n",
    "#  sort the composite dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{754: 0.5233423746109156, 575: 0.2848142035144489, 652: 0.2802216875233614, 516: 0.22757900209949142, 619: 0.15250819359772808, 947: 0.10916684924948701}\n",
      "Composite Similarity\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg']\n",
      "Composite Similarity Score:  0.5233423746109156\n",
      "Review Text:  use fender lock tuner five year variou strat tele definit help tune stabil way faster restr break\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/61n284XL9HL._SY88.jpg']\n",
      "Composite Similarity Score:  0.2848142035144489\n",
      "Review Text:  easi heck put opinion better sperzel took liter 10 minut put mim strat thing ill say probabl need setup remov tuner remov string guid tree headstock go chang angl bridg littl bit awar\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/719-SDMiOoL._SY88.jpg']\n",
      "Composite Similarity Score:  0.2802216875233614\n",
      "Review Text:  lock tuner look great keep tune good qualiti materi construct excel upgrad guitar drill addit hole instal neck alreadi come predril hole drop right otherwis need buy guitar tuner pin drill jig also avail amazon\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/51V0K2tgLUL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/5134EWdp6lL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/51m2jBw+onL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/51Xrb4h7gsL._SY88.jpg']\n",
      "Composite Similarity Score:  0.22757900209949142\n",
      "Review Text:  love guitar honestli never held squir brand strat compar everyth ive held play heard past guitar realli give best bang buck especi your like pretti much poor dirt thought guitar cheap id probabl want get small upgrad im pretti content got first 10 minut play recommend guitar pretti much anyon want strat incred qualiti price\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/61DvLcapd8L._SY88.jpg']\n",
      "Composite Similarity Score:  0.15250819359772808\n",
      "Review Text:  went fender chrome nonlock fender gold lock made guitar look beauti play beauti think lock tuner way go new lock tuner look youtub instruct\n",
      "Image URL ['https://images-na.ssl-images-amazon.com/images/I/71mhnYAH5VL._SY88.jpg']\n",
      "Composite Similarity Score:  0.10916684924948701\n",
      "Review Text:  tele perfect thank much\n"
     ]
    }
   ],
   "source": [
    "composite = dict(sorted(composite.items(), key=lambda item: item[1], reverse=True))\n",
    "print(composite)\n",
    "print(\"Composite Similarity\")\n",
    "for key, value in composite.items():\n",
    "    print(\"Image URL\",data.iloc[key]['Image'])\n",
    "    print(\"Composite Similarity Score: \",value)\n",
    "    print(\"Review Text: \", data.iloc[key]['Review Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
